{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"awsaf49/coco-2017-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def cartoonize_image(image_path, output_path):\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Étape 1 : Réduction des couleurs\n",
    "    num_down = 2  \n",
    "    num_bilateral = 7  \n",
    "    img_down = img.copy()\n",
    "    for _ in range(num_down):\n",
    "        img_down = cv2.pyrDown(img_down)\n",
    "    for _ in range(num_bilateral):\n",
    "        img_down = cv2.bilateralFilter(img_down, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "    img_up = img_down\n",
    "    for _ in range(num_down):\n",
    "        img_up = cv2.pyrUp(img_up)\n",
    "\n",
    "    # Resize img_up to match the original image size\n",
    "    img_up = cv2.resize(img_up, (img.shape[1], img.shape[0]))\n",
    "\n",
    "\n",
    "    # Étape 2 : Détection des contours\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.medianBlur(gray, 7)\n",
    "    edges = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 2)\n",
    "\n",
    "    # Étape 3 : Fusionner\n",
    "    cartoon = cv2.bitwise_and(img_up, img_up, mask=edges)\n",
    "\n",
    "    # Sauvegarde du résultat\n",
    "    cv2.imwrite(output_path, cartoon)\n",
    "\n",
    "# Exemple d'utilisation\n",
    "input_dir = \"dataset/real_images/\"\n",
    "output_dir = \"dataset/cartoonized/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for image_file in os.listdir(input_dir):\n",
    "    input_path = os.path.join(input_dir, image_file)\n",
    "    output_path = os.path.join(output_dir, image_file)\n",
    "    cartoonize_image(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "# Dossiers\n",
    "real_images = \"dataset/real_images\"\n",
    "cartoon_images = \"dataset/cartoonized/\"\n",
    "\n",
    "train_real = \"dataset/train/real/\"\n",
    "train_cartoon = \"dataset/train/cartoonized/\"\n",
    "test_real = \"dataset/test/real/\"\n",
    "test_cartoon = \"dataset/test/cartoonized/\"\n",
    "\n",
    "os.makedirs(train_real, exist_ok=True)\n",
    "os.makedirs(train_cartoon, exist_ok=True)\n",
    "os.makedirs(test_real, exist_ok=True)\n",
    "os.makedirs(test_cartoon, exist_ok=True)\n",
    "\n",
    "# Récupération des fichiers\n",
    "real_files = os.listdir(real_images)\n",
    "cartoon_files = os.listdir(cartoon_images)\n",
    "\n",
    "# Division\n",
    "train_files, test_files = train_test_split(real_files, test_size=0.2, random_state=42)\n",
    "\n",
    "# Copie des fichiers\n",
    "for file in train_files:\n",
    "    shutil.copy(os.path.join(real_images, file), os.path.join(train_real, file))\n",
    "    shutil.copy(os.path.join(cartoon_images, file), os.path.join(train_cartoon, file))\n",
    "\n",
    "for file in test_files:\n",
    "    shutil.copy(os.path.join(real_images, file), os.path.join(test_real, file))\n",
    "    shutil.copy(os.path.join(cartoon_images, file), os.path.join(test_cartoon, file))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
